{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use pytest in automatic code generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook shows you how to write a plugin for Pytest. This allows us to use the pytest functionaltiy, e.g. test-discovery, in our [automatic programming](https://arturmillerblog.wordpress.com/2017/07/15/automatic-programming/) scenario. Another advantage is that many developers are already familar with pytest. Therefor, it would be much easier for those people to apply this development technique.  \n",
    "We have seen in the post about [Abstract Syntax Trees](https://arturmillerblog.wordpress.com/2017/08/06/abstract-syntax-tree/), that programs can be describe in a tree structure, with each node being an expression. Each permutation of the expressions is different program. Therefor, the number of all possible programs growth exponetially with the length of the program. This makes creating executable code from given tests a hard problem.  \n",
    "This problem can only be solved by using machine learning or statistics techniques. The usage of these approaches will be introduced in a future post. This post is about pytest and how to utilize it in our scenario. Nevertheless, we are going to generate a simplistic function in this notebook. The function gets three arguments as input and returns the sum of these arguments. We generate new functions until one is found that fullfills the four given tests. These tests are defined in the TestSpecialAdd.py module. The following cell shows these tests. Initially I had planned to implement these tests within this notebook, however I couldn't find an easy solution to run these tests with pytest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def test_a():\n",
      "    assert special_add(2, 3, 4) == 9  # @UndefinedVariable\n",
      "\n",
      "\n",
      "def test_b():\n",
      "    assert special_add(1, 1, 0) == 2  # @UndefinedVariable\n",
      "\n",
      "\n",
      "def test_c():\n",
      "    assert special_add(10, 2, 4) == 16  # @UndefinedVariable\n",
      "\n",
      "\n",
      "def test_d():\n",
      "    assert special_add(0, -5, 6) == 1  # @UndefinedVariable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import templates.TestSpecialAdd as TestSpecialAdd\n",
    "\n",
    "tests_path = os.path.splitext(TestSpecialAdd.__file__)[0] + '.py'\n",
    "with open(tests_path, 'r') as tests_file:\n",
    "    print(tests_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class CodeGenerator creates new possible functions which are confrontet with the tests. The code generator is only able to create a small number of functions from the whole set of all possible python programs. These functions have always three arguments x, y, z and they return the result of an operation. The operation is an addition, subtraction, multiplication or division and is sampled randomly. An operation gets two variables as input. The variable is in 40% of the cases one the arguments and otherwise the result of another operation. In this way functions with varying length are produced in a recursive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "\n",
    "class CodeGenerator():\n",
    "    def __init__(self):\n",
    "        self.arguments = [ast.Name(id='x', ctx=ast.Param()),\n",
    "                          ast.Name(id='y', ctx=ast.Param()),\n",
    "                          ast.Name(id='z', ctx=ast.Param())]\n",
    "\n",
    "        self.variables = [ast.Name(id='x', ctx=ast.Load()),\n",
    "                          ast.Name(id='y', ctx=ast.Load()),\n",
    "                          ast.Name(id='z', ctx=ast.Load())]\n",
    "\n",
    "        self.operations = [ast.Add(), ast.Sub(), ast.Mult(), ast.Div()]\n",
    "\n",
    "    def sample_variable(self):\n",
    "        return random.choice(self.variables)\n",
    "\n",
    "    def sample_operation(self):\n",
    "        return random.choice(self.operations)\n",
    "\n",
    "    def get_operation_or_variable(self):\n",
    "        if random.uniform(0.0, 1.0) > 0.6:\n",
    "            return self.get_operation()\n",
    "        else:\n",
    "            return self.sample_variable()\n",
    "\n",
    "    def get_operation(self):\n",
    "        return ast.BinOp(op=self.sample_operation(), left=self.get_operation_or_variable(), right=self.get_operation_or_variable())\n",
    "\n",
    "    def sample_function(self):\n",
    "        arguments = ast.arguments(args=self.arguments, vararg=None, kwarg=None, defaults=[])\n",
    "        func = ast.FunctionDef(name='special_add', args=arguments, body=[ast.Return(value=self.get_operation())], decorator_list=[])\n",
    "        ast_module = ast.fix_missing_locations(ast.Module(body=[func]))\n",
    "        return ast_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function has_passed checks whether a generated function passes a certain test or not. It runs the function and return true if no exception is raised, which would be the case when the test failed, otherwise it returns false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def has_passed(special_add, tests):\n",
    "    for test in tests:\n",
    "        current_func = copy.deepcopy(test.function)\n",
    "        current_func.func_globals['special_add'] = special_add\n",
    "        try:\n",
    "            current_func()\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we exploit pytest to generate source code for the unittests. Pytest allows us to define plugins, which hook to certain events, e.g. before a test is running or before a file searched for tests. We utilize the itemcollected hook to store found tests to further use and run the code generation in the runtestloop hook. New code is generated in a loop as long as no function is found that passes all tests. The code is compiled and run with the exec keyword and build-in compile function. At the end the resulting code is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 2.7.13, pytest-3.0.5, py-1.4.32, pluggy-0.4.0\n",
      "rootdir: C:\\Users\\Artur\\Development\\workspace\\MachineLearning, inifile: \n",
      "collected 4 items\n",
      "number of samples: 229\n",
      "\n",
      "def special_add(x, y, z):\n",
      "    return z + x + y\n",
      "\n",
      "..\\templates\\TestSpecialAdd.py ....\n",
      "\n",
      "========================== 4 passed in 0.12 seconds ===========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest\n",
    "import codegen\n",
    "\n",
    "class CodeGeneratorPlugin(object):\n",
    "    def __init__(self):\n",
    "        self.tests = []\n",
    "\n",
    "    def pytest_itemcollected(self, item):\n",
    "        self.tests.append(item)\n",
    "\n",
    "    def pytest_runtestloop(self, session):\n",
    "        code_generator = CodeGenerator()\n",
    "\n",
    "        found = False\n",
    "        num_samples = 0\n",
    "        while not found:\n",
    "            ast_module = code_generator.sample_function()\n",
    "            exec compile(ast_module, '<string>', 'exec') in globals(), locals()\n",
    "            found = has_passed(special_add, self.tests)\n",
    "            num_samples += 1\n",
    "\n",
    "        print('number of samples: {}\\n'.format(num_samples) )\n",
    "        print(codegen.to_source(ast_module))\n",
    "\n",
    "pytest.main([tests_path], plugins=[CodeGeneratorPlugin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the code generation works quite well. After several randomly generated functions, a function is found that actually passes all tests and is in fact a proper implementation of what we wanted to achive.  \n",
    "In this case four tests are enough to specify how the implementation should look like. I have tried to generate code with less than four tests. The generator found quite often solutions, where the tests passed but it was nevertheless a wrong implementation.  \n",
    "A difficulty is to deal with trivial variations. For example the return value is always the same, if it is multiplied 1. A 1 is generated easily, by creating an e.g. x/x. The biggest challenges are how to scale to much more versatile generated code and to a huge number of tests. As I already meantioned this could be handled by machine learning or statistics techniques. We will try it out in a future post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
