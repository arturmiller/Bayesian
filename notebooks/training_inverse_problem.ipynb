{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the third part of my series about inverse problems. In the first [post](https://miller-blog.com/inverse-problem-part-1/), based on a simple toy example, I have introduced the concept of inverse problems. The second [post](https://miller-blog.com/inverse-problem-part-2/) showed a more complicated problem, the classification of images showing digits. The model has not been trained on training data. Instead the generative model (the class is the causal factor and the image is the observation) was given. Each row is an example image of the digits 0-9. The question I want to investigate in this post is, whether it is somehow possible to train such a generative model. In fact training a machine learning problem is an inverse problem in itself. That is why neural networks are trained iteratively, utilizing the back-propagation algorithm. Back-propagation is just a special case of calculating the gradient of the loss function of a neural network.  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/arturmiller/MachineLearning/master/notebooks/images/classification_as_inversion.svg?sanitize=true\" width=\"40%\"/>   \n",
    "\n",
    "As already mentioned in this blog post my goal is to classify images of digits. Exactly as in the last article the causal factors $\\mathbf{z}$ of the digit images are found, by optimizing a loss function $L_{generative}$. The loss function penalizes the deviation of the image $\\mathbf{X}$ and the projection $G_{\\phi}(\\mathbf{z})$.  \n",
    " \n",
    "\n",
    "definition losses:\n",
    "$$L_{generative}=\\frac{1}{J}\\sum_{j=1}^J{(X_j-G_\\mathbf{\\phi}(z_j))^2}$$\n",
    "$$p=\\mathrm{logistic}(F_\\mathbf{\\theta}(\\mathbf{z^*}))=\\frac{1}{1+e^{-F_\\mathbf{\\theta}(\\mathbf{z^*})}}$$\n",
    "$$L_{target}=-\\frac{1}{K}\\sum_{k=1}^K {(y_k \\log(p_k)+(1−y_k) \\log(1−p_k))}$$\n",
    "\n",
    "best parameters:\n",
    "$$\\mathbf{z^*}=\\underset{\\mathbf{z}}{\\operatorname{argmin}}(L_{generative})$$\n",
    "$$\\mathbf{\\theta^*},\\mathbf{\\phi^*}=\\underset{\\mathbf{\\theta},\\mathbf{\\phi}}{\\operatorname{argmin}}(L_{target})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $m = 1\\dots M:$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $L_{generative}=\\frac{1}{J}\\sum_{j=1}^J{(X_j-G_\\mathbf{\\phi}(z_j))^2}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; for $n = 1\\dots N:$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\mathbf{z_n}=\\mathbf{z_{n-1}}-\\alpha \\frac{\\mathrm d}{\\mathrm d z}\\big(L_{generative}\\big)$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $z^*=z^N$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $p=\\mathrm{logistic}(F_\\mathbf{\\theta}(\\mathbf{z^*}))$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $L_{target}=-\\frac{1}{K}\\sum_{k=1}^K {(y_k \\log(p_k)+(1−y_k) \\log(1−p_k))}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $\\theta_{m}=\\theta_{m-1}-\\beta\\frac{\\mathrm d}{\\mathrm d \\theta}\\big(L_{target}\\big)$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $\\phi_{m}=\\phi_{m-1}-\\gamma\\frac{\\mathrm d}{\\mathrm d \\phi}\\big(L_{target}\\big)$  \n",
    "$\\theta^*=\\theta^M$  \n",
    "$\\phi^*=\\phi^M$  \n",
    "<img src=\"https://github.com/arturmiller/MachineLearning/blob/master/notebooks/images/inverse_net.png?raw=true\" width=\"30%\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change loss with tf.losses.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-b10a21223d58>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-b10a21223d58>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    next_latent_params = latent_params - tf.multiply(gen_learning_rate, grad)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class InverseNet(object):\n",
    "    def __init__(self, num_latent_params=10, learning_rate=5e-4, seed=42, iter_inner_loop=500, iter_outer_loop=50):\n",
    "        self.num_latent_params = num_latent_params\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        self.loss_history = []\n",
    "        self.iter_inner_loop = iter_inner_loop\n",
    "        self.iter_outer_loop = iter_outer_loop\n",
    "\n",
    "    def tf_gen_model(self, latent_params, model_params, X, gen_learning_rate=1e-2):\n",
    "        tf_output = tf.transpose(tf.matmul(model_params, latent_params))\n",
    "        loss = tf.losses.mean_squared_error(X, tf_output)\n",
    "        grad = tf.gradients(loss, [latent_params])[0]\n",
    "\n",
    "        next_latent_params = latent_params - tf.multiply(gen_learning_rate, grad)\n",
    "        return next_latent_params\n",
    "\n",
    "    def tf_iter_latent_params(self, X, latent_params, model_params):\n",
    "        for i in range(self.iter_inner_loop):\n",
    "            latent_params = self.tf_gen_model(latent_params, model_params, X)\n",
    "        return latent_params\n",
    "\n",
    "    def tf_calc_outer_loss(self, X, y, latent_params, model_params):\n",
    "        latent_params = self.tf_iter_latent_params(X, latent_params, model_params)\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=tf.transpose(latent_params))\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        latent_shape = (self.num_latent_params, np.size(X, axis=0))\n",
    "        tf_latent_params = tf.constant(np.abs(np.random.randn(*latent_shape)) / 100.0, dtype=tf.float32)\n",
    "        tf_y = tf.constant(y, dtype=tf.float32)\n",
    "\n",
    "\n",
    "        model_shape = (np.size(X, axis=1), self.num_latent_params)\n",
    "        tf_model_params = tf.Variable(np.abs(np.random.randn(*model_shape)) / 100.0, dtype=tf.float32)#, constraint=positive)\n",
    "\n",
    "        tf_X = tf.constant(X, dtype=tf.float32)\n",
    "        L2 = self.tf_calc_outer_loss(tf_X, tf_y, tf_latent_params, tf_model_params)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        train = optimizer.minimize(L2)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "        def eval_step(i=0):\n",
    "            tmp_loss = sess.run(L2)\n",
    "            self.loss_history.append(tmp_loss)\n",
    "            print_loss_number = int(self.iter_outer_loop / 20)\n",
    "            if i % print_loss_number == 0:\n",
    "                print('index: {} loss: {}'.format(i, tmp_loss), end='\\r')\n",
    "\n",
    "        for i in range(self.iter_outer_loop):\n",
    "            eval_step(i)\n",
    "            sess.run(train)\n",
    "\n",
    "        self.model_params = sess.run(tf_model_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tf_X = tf.constant(X, dtype=tf.float32)\n",
    "        latent_shape = (self.num_latent_params, np.size(X, axis=0))\n",
    "        tf_latent_params = tf.constant(np.abs(np.random.randn(*latent_shape)) / 100.0, dtype=tf.float32)\n",
    "        tf_model_params = tf.constant(self.model_params, dtype=tf.float32)\n",
    "        tf_res_latent_params = self.tf_iter_latent_params(tf_X, tf_latent_params, tf_model_params)\n",
    "        tf_label = tf.argmax(tf_res_latent_params, axis=0)\n",
    "        sess = tf.Session()\n",
    "        label = sess.run(tf_label)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "digits = datasets.load_digits(10)\n",
    "\n",
    "def plot_digits(images):\n",
    "    f, ax = plt.subplots(2, 5, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            ax[i, j].imshow(\n",
    "                images[i * 5 + j, :].reshape(8, 8), cmap='gray_r')\n",
    "    plt.show()\n",
    "plot_digits(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(10, sparse=False)\n",
    "\n",
    "def plot_loss(loss):\n",
    "    plt.plot(loss)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "def train_data(num_train, learning_rate, iter_outer_loop):\n",
    "    n_samples = len(digits.images)\n",
    "    data = digits.images.reshape((n_samples, -1))\n",
    "    loss_net = InverseNet(learning_rate=learning_rate, iter_inner_loop=250, iter_outer_loop=iter_outer_loop)\n",
    "    X = data[:num_train, :]\n",
    "    y = enc.fit_transform(digits.target[:num_train].reshape((-1, 1)))\n",
    "    loss_net.fit(X, y)\n",
    "    predicted = loss_net.predict(data[1000:1500, :])\n",
    "    accuracy = np.sum(digits.target[1000:1500] == predicted)\n",
    "    print('\\naccuracy: {}%'.format(accuracy/5.0))\n",
    "    \n",
    "    plot_loss(loss_net.loss_history)\n",
    "    plot_digits(loss_net.model_params.T)\n",
    "    plt.show()\n",
    "    \n",
    "train_data(10, 1e1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 1800 loss: 2.2535371780395513\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5ad41b70fc40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-a768eaf98840>\u001b[0m in \u001b[0;36mtrain_data\u001b[1;34m(num_train, learning_rate, iter_outer_loop)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mloss_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-4d3fcb1f10fd>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_outer_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0meval_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_model_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Development\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Development\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Development\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Development\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Development\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Development\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data(1000, 1e2, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
